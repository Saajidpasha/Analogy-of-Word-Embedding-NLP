{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to you first hands-on on word embeddings.\n",
    "#### In this hands-on you will be using pretrained GLoVe word vectors from stanford nlp which you can find [here](https://nlp.stanford.edu/projects/glove/)\n",
    "#### Each word vectors is of dimension 50\n",
    "#### You will be performing following operations:\n",
    "    - Load the pretrained vectors from the text file\n",
    "    - Write a function to find cosine similarity between two word vectors\n",
    "    - Write an function to find analogy analogy problems such as King : Queen :: Men : __?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1\n",
    "- A text file having the trained word vectors is provided for you as word2vec.txt in the same working directory.\n",
    "- Each line in the file is space seperated values where first value is the word and the remaing values are its vector representation.\n",
    "\n",
    "### Define a function get_word_vectors()\n",
    "    parameters: file_name  \n",
    "    returns: word_to_vec: dictionary with key as the word and the value is the corresponding word vectors as 1-d array each element of type float32.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def get_word_vectors(file_name):\n",
    "    ###Start code here\n",
    "    word_to_vec = {}\n",
    "    df = pd.read_csv(file_name,sep=\" \",quoting=3,header=None,index_col=0)\n",
    "    word_to_vec = {key : val.values for key,val in df.T.items()}\n",
    "\n",
    "    return word_to_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the function you defined above read the word vectors from the file word_vectors.txt and assign it to variable word_to_vec\n",
    "\n",
    "### Expected output  (showing only first few values of vectors)\n",
    "   Father:  [ 0.095496   0.70418   -0.40777   -0.80844    1.256      0.77071 ...]  \n",
    "   mother:  [ 0.4336     1.0727    -0.6196    -0.80679    1.2519     1.3767 ....]  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Father:  [ 0.095496   0.70418   -0.40777   -0.80844    1.256      0.77071\n",
      " -1.0695     0.76847   -0.87813   -0.0080954  0.43884    1.0476\n",
      " -0.45071   -0.58931    0.83246   -0.038442  -0.73533    0.26389\n",
      "  0.12617    0.57623   -0.23866    1.0922    -0.3367     0.081537\n",
      "  0.84798   -2.4795    -0.40351   -0.84087    0.12034    0.29074\n",
      "  1.9711    -0.50886   -0.45977   -0.13617    0.55613    0.22924\n",
      " -0.18947    0.43544    0.65151    0.043537  -0.1162     0.72196\n",
      " -0.66163   -0.17272    0.27367   -0.28169   -0.82025   -1.5089\n",
      "  0.052787  -0.035579 ]\n",
      "mother:  [ 0.4336     1.0727    -0.6196    -0.80679    1.2519     1.3767\n",
      " -0.93533    0.76088   -0.0056654 -0.063649   0.30297    0.52401\n",
      "  0.2843    -0.38162    0.98797    0.093184  -1.1464     0.070523\n",
      "  0.58012    0.50644   -0.24026    1.7344     0.020735   0.43704\n",
      "  1.2148    -2.2483    -0.41168   -0.24922    0.31225   -0.49464\n",
      "  2.0441    -0.012111  -0.19556    0.085665   0.27682    0.015702\n",
      "  0.0067683  0.12759    0.87008   -0.40641   -0.21057    0.41651\n",
      " -0.021812  -0.53649    0.54095   -0.43442   -0.52489   -2.0277\n",
      "  0.13136    0.11704  ]\n"
     ]
    }
   ],
   "source": [
    "word_to_vec = get_word_vectors('word2vec.txt')\n",
    "father = word_to_vec[\"father\"]\n",
    "mother = word_to_vec[\"mother\"]\n",
    "print(\"Father: \", father)\n",
    "print(\"mother: \", mother)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2 Determine the cosine similarity between two word vectors\n",
    "- The formula for cosine similarity is given by\n",
    "  score = $\\large \\frac{U.V}{\\sqrt{||U||.||V||}}$ where ||U|| and ||V|| is the sum of the squares of the elemnts individual vectors\n",
    "  \n",
    "\n",
    "### Define a function named cosine_similarity()\n",
    "    - parameters u, v are the word vectors whose similarity has to be determined\n",
    "    - returns - score: cosine similarity of u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    dot = np.dot(u,v)\n",
    "    \n",
    "    norm_u = np.sqrt(np.sum(u * u))\n",
    "    \n",
    "   \n",
    "    norm_v = np.sqrt(np.sum(v * v))\n",
    "   \n",
    "    score = dot / (norm_u * norm_v)\n",
    "   \n",
    "    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the bellow cell to find the similarity between word vectors paris and rome\n",
    "### Expected output\n",
    "   similarity score : 0.7099411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score : 0.7099411341712598\n"
     ]
    }
   ],
   "source": [
    "paris = word_to_vec[\"paris\"]\n",
    "rome = word_to_vec[\"rome\"]\n",
    "print(\"similarity score :\", cosine_similarity(paris, rome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "In the word analogy task, we complete the analogy . In detail, we are trying to find a word d, such that the associated word vectors $u_1, v_1, u_2, v_2$ are related in the following manner: $u_1 - v_1 \\approx u_2 - v_2$. We will measure the similarity between $u_1 - v_1$ and $u_2 - v_2$ using cosine similarity.\n",
    "#### As an example,  to find the best possible word for the analogy King : Queen :: Men : __?_ you will perform following steps:\n",
    "- extract word vectors of three words king, queen and men\n",
    "- find the element wise difference between the two word vectors king and queen as V1\n",
    "- Find the element wise difference between the word vector men and each word vector in word_to_vec ditionary as V2 (while doing so exclude the words of interest ie. king, queen and men)\n",
    "- Find the cosine similarity between vector V1 and V2 and choose the word from the word_to_vec ditionary that has maximum similarity between V1 and V2.\n",
    "### Define the function named find_analogy()\n",
    "    - parameters: word1 - string corresponding to word vector $u_1$\n",
    "                  word2 - string corresponding to word vector $v_1$\n",
    "                  word3 - string corresponding to word vector $u_2$\n",
    "                  word_to_vec - dictionary of words and their corresponding vectors\n",
    "    - returns: best_word -  the word such that $u_1$ - $v_1$ is close to $v\\_best\\_word$ - $v_c$, as measured by cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(word_1, word_2, word_3, word_to_vec_map):\n",
    "    word_a, word_b, word_c = word_1.lower(), word_2.lower(), word_3.lower()\n",
    "      \n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "    \n",
    "    \n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -100              \n",
    "    best_word = None   \n",
    "    for w in words:        \n",
    "        \n",
    "        if w in [word_a, word_b, word_c] :\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below  code to evaluate your above defined function\n",
    "\n",
    "#### Expected output:\n",
    "    father -> son :: mother -> daughter\n",
    "    india -> delhi :: japan -> tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father -> son :: mother -> daughter\n",
      "india -> delhi :: japan -> tokyo\n"
     ]
    }
   ],
   "source": [
    "print ('{} -> {} :: {} -> {}'.format('father', 'son', 'mother',find_analogy('father', 'son', 'mother', word_to_vec)))\n",
    "print ('{} -> {} :: {} -> {}'.format('india', 'delhi', 'japan',find_analogy('india', 'delhi', 'japan', word_to_vec)))\n",
    "\n",
    "word1 = find_analogy(\"spain\", 'india', 'tokyo', word_to_vec)\n",
    "word2 = find_analogy(\"small\", 'smaller', 'large', word_to_vec)\n",
    "\n",
    "with open(\"output.txt\", 'w+') as file:\n",
    "    file.write(word1+'\\n')\n",
    "    file.write(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
